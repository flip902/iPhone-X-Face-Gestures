# iPhone-X-Face-Gestures
The goal of this project was to prototype an app that controls an iPhone X with face gestures. It is written in Swift and was constructed in Xcode. The app will only run on an iPhone X because Apple's TrueDepth camera is the hardware that makes it possible. The code uses Apple's ARKit library to access the 3D face model generated by the TrueDepth camera, which is how face gestures are recognized under the hood. Specifically, however, this app recognizes face gestures through the **FaceTrigger** class written by GitHub user *barnaclejive*. His FaceTrigger repository can be found here: https://github.com/barnaclejive/FaceTrigger

The novelty in this app is the interface that the face gestures control. It's a simple app with only two tabs; one tab is a "busy box" of UI elements that are controlled by face gestures, and the other tab allows users to pick which gestures control which elements.

TODO: "Include a readme file that documents what's in your source repository."

TODO: "It is extremely important that you document any work that you used that originally came from somewhere else, including libraries, as well as code examples copied from StackOverflow and similar. You should be very careful about documenting all your sources."

TODO: "What to submit:
A zip file containing your source files, with a readme file that explains what everything is
A 1-2 page PDF document describing your user test and results.
An HTML or PDF document that provides detailed instructions for building and running your project"
